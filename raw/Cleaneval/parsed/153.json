{
  "url": "http://ref.web.cern.ch/ref/CERN/CNL/2001/002/cern-computing/",
  "content_hash": "840aec77694cd34fdaea65dd652641ed0662d6582c9217113b8aa84c0dadbd19",
  "total_blocks": 87,
  "retained_blocks": 9,
  "ignored_blocks": 78,
  "blocks": [
    {
      "tag": "h4",
      "text": "Contents"
    },
    {
      "tag": "div",
      "text": "Editorial Information Editorial If you need help Announcements Free Access to Gartner Group Reports within CERN Special 35th Anniversary 30 Years of Computing at CERN - Part 1 GISMO Project: Historical Details Physics Computing US Award for CERN Computing European Union Gives 9.8 million Euros for GRID Development (January News) Move from HPSS to Castor  : Will the hsm\nCommand be Transparent? Desktop Computing NICE (Windows) 2000 Migration News Usage Generalisation of a Problem Report Management\nSystem for Problem Tracking in IT Division Internet Services and Network Computer Security at CERN: Risks are Increasing LocalTalk Networking End Scientific Applications and Software Engineering 2001 CERNLIB Release Future of CERNLIB Software Development Tool Service Desktop Publishing XML Applications at CERN The latest LATEX The Learning Zone Computing at CERN, Once Upon a Time... Questions and Answers from the Computing Helpdesk User Documentation User Support Book Catalogue Previous: Special 35th Anniversary Next: GISMO Project: Historical Details (See printing version)"
    },
    {
      "tag": "h2",
      "text": "30 Years of Computing at CERN - Part 1"
    },
    {
      "tag": "p",
      "text": "Paolo Zanella , Former Division Leader of DD"
    },
    {
      "tag": "h4",
      "text": "Abstract"
    },
    {
      "tag": "p",
      "text": "This is the first of a three-part series,\nmade out of the original (excellent) paper\nwritten by Paolo Zanella\nin 1990. I hope that it can serve future Computorians\nto write \"IT at CERN: its birth, its life ...\" - Miguel Marquina (editor)- 1. INTRODUCTION The origins of computing machinery can be traced back to 3000\nyears ago when the Chinese introduced a primitive form of abacus,\nor 300 years ago when Schickard, Pascal and Leibniz invented the\nfirst arithmetic machines. For us at CERN it all started 30 years\nago when one of the first electronic digital computers, a huge\nFerranti Mercury, was installed. It was the beginning of a success\nstory which has changed the way to do physics and, as a matter of\nfact, to do any work at all in the Laboratory. The story goes on and the changes brought in by the new\ninformation technologies continue to affect us at an astonishing\nrate. Those who witnessed the beginning of the information era were\nconscious of the potential impact of those mar marvellous machines\non Physics as well as on Society, but they could hardly imagine\nwhat was to come. In retrospect, we can say that the 30 years which\nseparate us from the days of those first generation machines, have\nbeen years of struggle, of sweat and tea tears, of doubt and of\npainful reappraisal, but also years of discovery, of excitement, of\nachievement and of pride to the actors in this unique\nadventure. Of those 30 CERN years, I missed only the first three. I did not\nmiss, however, the joys of programming first generation machines,\nalthough in a different environment. Actually, when I joined CERN\nearly in 1962, the only machines around were still made out of\nvacuum tubes. I am, therefore, rather well placed to tell my\npersonal account of the what, why and how of the evolution\nof automatic computing at CERN. I shall not even attempt to be exhaustive, let alone objective.\nI shall tell the story as I saw it, or rather as I lived it.\nInstead of compressing 262800 hours into 1, I shall select and\nreport only those events which, in my opinion, are either real\nmilestones or make an interesting story, and I shall follow them\nthrough to their consequences, even if this means breaking the\nstrict chronological order. The basic features of the large\nhigh-performance systems which have played a major role in the CERN\nComputer Center are listed in Appendix\n1 . 2. THE BIG BANG It took six days for God to build the Universe and a little over\ntwo years for the Ferranti engineers to produce our Mercury ,\na large assembly of complex circuitry hidden inside a row of\naustere cabinets, making few concessions ons to people's curiosity.\nAt about the same time the PS was built in five years and today one\ncan build accelerators 1000 times more powerful, always in about\nfive years. The Mercury was 1000 times less powerful (16.6 kHz)\nthan a modern personal computer which is now mass-produced by\nrobotized assembly lines at the rate of 2 or 3 per minute! The purchasing contract was signed on the 25th of May, 1956 and\nstipulated that the machine with 1024 40-bit words of fast [ 120 microsec to read/write one word from the\naccumulator] core store and a slow [8.75 msec\nlatency] drum store having a total capacity of 16384\nwords of 40 binary digits, would be shipped to CERN in early\nFebruary 1957 and installation shall be completed by 1st May,\n1957.... The details of the progress of manufacture will be\nsubmitted at intervals of one month. The Mercury had a clock\ncycle of 60 microsec. It took 180 microsec to add and 300 microsec\nto multiply two long words of 40 bits. It had floating point\narithmetic. Division, however, had to be programmed. It is\ninteresting to note the absence of the word software from\nthe contract, the only relevant mention being: any programs and\nsub-routines which Ferranti will prepare will be made available to\nCERN free of charge. Unbundling and licensing were unknown\nin the 50's. The computer actually arrived during the summer of 1958 and passed the acceptance tests in October of that year. Following\nits successful introduction, a thick file of orders revealed the\nurgent need for spare valves and of tape bins (a critical\ndevice in those days of punched paper tape input/output!). At the end of 1958, the availability of a programming language\ncalled Autocode , attracted the first users to\nthe computer centre and marked the beginning of the 30 years of\ncomputing covered by this paper. It is interesting to note that the\nfirst Mercury Autocode compiler was written in 1956\n(by R. A. Brooker), two years before the appearance of the first FORTRAN compiler! It had many features which appeared later\nin FORTRAN. Due to memory limitations, variable names were\nrestricted to a single alphabetic character (5-bit Ferranti code).\nIt is worth noting that in the mid 50's the European computer\nindustry was still competitive. As far as competence, innovative\nideas and successful products are concerned, European companies\nlike Ferranti, English Electric and Elliott in England, Telefunken in Germany and Bull in France had little to envy their American\ncompetitors (e.g. ERA/Remington Rand, NCR, IBM ). The\nsize and the drive of the American market were, however, going to\nmake the difference quite rapidly in the 60's. The reasons behind the decision to acquire a Mercury were\ntechnical, political and financial. Technically the Mercury was\ndefinitely one of the most advanced machines around. It was\nconsidered superior to the Ferranti Pegasus, to the Elliott 404, to\nthe English Electric 'Deuce', to the Bull 'Gamma 311' and to\ndrum-type machines like the IBM 650. Ferranti was set up to produce\na dozen units and CERN was going to get serial number 6. The fact\nthat Harwell and Saclay had ordered Mercury's was given a certain\nweight. CERN had no experience in electronic digital computers and\nit was better to be part of a club of users. As to the price (one\nmillion Swiss Francs), it was five times cheaper than equivalent\nAmerican machines like the ERA 1101. Discussions went on for several months at CERN in 1955 and 1956.\nExternal experts were involved. Fifteen years after Konrad Zuse's\nrelay-based Z3 considered by many as the first general purpose\ncomputer, ten years after the electronic ENIAC, and six years after\nMaurice Wilkes' EDSAC, people were still debating on the virtues of\nbinary versus decimal machines, on the importance of floating point\narithmetic, on the size of words (the Z3 had 22-bit and the EDSAC\n32-bit words; the ENIAC was a decimal machine with 10 digits\nwords. The size of central memory was 64 words for the Z3, 2n for\nthe ENIAC and 512 for the EDSAQ, and on the best way to input and\noutput data (punched film, 5-7-8 channels papertape, or cards).\nPractical problems had to do with the unreliability of the\nhardware, the organization of the operations and the recruitment of\nexperts. Obsolescence was already a problem. CERN decided that the machine should be purely binary, that\n32-bit words were too short, and that the speed should be as high\nas possible (in particular multiplication time should be under a\nmillisecond). It also concluded that the speed and size of\nmemory were very important (several tens of thousands of binary\ndigits were a clear necessity), while the availability of\nfloating point hardware was considered a very desirable,\nalthough not quite indispensable, feature of a scientific\ncomputer. But what really makes it worthwhile to have a\nmachine, is the enthusiasm for carrying out the most difficult\ncomputations, as an American physicist put it in a letter\ndescribing his experience with a digital computer or 'the\ncourage to go ahead and solve problems which would have seemed too\ndifficult to do otherwise.' The computers of that time had colorful names like ILLIAC at the\nUniversity of Illinois, AVIDAC at Argonne, MANIAC, UNIVAC, etc...\nMost of them were prototypes. Everything was very much\nexperimental. The operations arrangements at the ILLIAC were\ndescribed as follows: 'The user deposits his punched paper tape\nin a box with instructions or the operator. The operator takes\nthese tapes, and inserts them in the machine in turn. If the code\nis correct, the machine delivers the answers and these may be\npicked up by the user the next morning. If there are errors in the\ncode, the operator carries out the test routines requested and the\nresults of these tests are deposited so that these may be reviewed\nby the user the next morning. Thus, the whole operation of the\nmachine becomes a fairly automatic affair'. This was more or\nless the style adopted for our operations thirty years ago. One of the first applications at CERN was the analysis of the\npapertape produced by the Instruments for the Evaluation of\nPhotographs (IEPs), used to scan and measure bubble chamber film.\nThe first reports convey a certain deception due to the slow tape\nread/write speed. Since everything had to go through the\naccumulator, the CPU was blocked during I/0. It was immediately\nclear that there was a big mismatch between the power of the\ncomputing engine and its input/output capability. After some struggling with faulty tubes, tape bins, machine\ninstructions and Autocode , people with lots of data\ndiscovered the existence of an IBM 704 in Paris, which offered\nsignificant advantages such as magnetic tape units, card\nreaders, line printers and FORTRAN! FORTRAN II allowed\n6-characters variable names and, most important, it simplified the\nexchange of programs with Berkeley and Brookhaven. The 1959 CERN\nAnnual Report indicated already that as the needs\nincrease, it will be necessary to envisage the replacement of the\nMercury by a more powerful system. It was also quickly realized\nthat these so-called electronic brains required quite a lot of\nhuman effort to be effectively exploited. Hence the proposal to\ndouble in 1960 the computer center staff (from 10 to 20). So, by the end of the 50's, the fundamental forces, sociological\nand technological, characteristic of every computer service, had\nbeen discovered, including the illusion that upgrading the\nresources would solve all the problems and achieve the ultimate\ngoal, i.e. make the users happy! 3. THE LESSONS OF THE EARLY 60'S The next big news was the arrival of the IBM 709, an\nimproved version of the 704, in January 1961. It was still a clumsy\nvacuum tube machine but it featured FORTRAN and all those fancy\nperipherals apt to improve the quality of life . The word length was 36 bits, the characters became 6-bit BCD,\nand the core memory size jumped to 32K. The CPU was 4-5 times\nfaster than that of the Mercury. However, to compile a typical\nFORTRAN program could take several minutes! Tape bins made way\nfor card trays. Magnetic tape units read and wrote at 75 ips on 7\ntracks and the density was 200 bpi. Peripherals were attached via\ntheir controllers to data channels. It was a significant advance in\nthat it allowed as many as six peripheral devices to access core\nmemory buffers while the CPU performed other work. Another\nimportant device which came with the 709 was the so-called Direct\nData Connection, allowing for direct transmission of data from\nexternal equipment to memory via a channel. The speed was not\nridiculous: in principle up to 1 Megabit/sec. The 709 was also\nequipped with one of the first interrupt systems. The bad news was still the poor reliability, although the\nprogress was already quite substantial. Unscheduled maintenance\nrepresented 11% of the total time. Scheduled maintenance took away\na time slice of similar size. So the down-time of the 709 compared\nnot too unfavorably with the up time of the very first electronic\ncomputers.... The on-line card reader and the printer did, however,\nslow down the operations considerably. After one year of experience\nCERN added a small IBM 1401, in order to speed up the input/output,\nthe job sequencing and the operations. The concept of SPOOLing\n(Simultaneous Peripheral Operation On-Line) with its 1/0 files\n(virtual reader/printer) has its origins in those days. Programming\nfor the 709 was considered a difficult activity to be left to the\nspecialists who could understand and keep up-to-date with the new\ntechniques and the operating conventions. The machine was an\nexpensive resource which had to be used efficiently. To give an\nidea, the list price was in the region of ten millions francs\n(1960 Swiss francs!). In those days a magnetic tape cost 60 $\n(some 260 SF!). It was at that time that the first inescapable\ncommittees appeared, e.g. Computer Scheduling Committee,\nComputer Users Advisory Committee and the Data Handling Policy\nGroup. The Mercury had still its faithful users but suffered from the\nchronic lack of modern, fast peripherals. In 1962, as part of a\nlifting operation, it was enhanced by the connection of an Ampex\ntape unit, compatible with IBM specifications and operating\nat 3333 characters per second (over 3 times the speed of the\nfastest paper tape reader and some 20 times faster than a tape\npunch). Also, two papertape-to-card converters were installed to\nease the transfer of data from the Mercury to the 709. By the\nend of 1962 it was possible to read the paper tape from IEPs into\nthe Mercury, give it a first processing pass, write the results\non magnetic tape and input it onto the IBM 709 for further\nanalysis. The first application packages appeared at that time,\ne.g. THRESH and GRIND used for the geometrical reconstruction and\nkinematic analysis of bubble chamber events. It is amusing to note\nthat, in spite of the growing workload and the frantic development\nof codes, the machines were normally switched off at weekends. But\nthe practice of 24 hours/day, 7-days/week service was around the\ncorner. It is also in interesting to realize that things like the\nconnection of the Ampex tape unit to the Mercury were entirely\ndesigned and implemented on site. The next problem was how to use all those Autocode programs on the 709. One just wrote an Autocode compiler for the 709. The difficulties of developing software were\nsoon to be learned. The first Conference recognizing the existence\nof a software crisis was held in Munich in 1968. Why is software\nalways late and unreliable? People working today with modern CASE\n(Computer Assisted Software Engineering) or OOP (Object Oriented\nProgramming) tools are still trying to solve the problem. But the\nanswer in those days was: better programming languages . CERN FORTRAN was defined to ensure compatibility with other\nlaboratories and facilitate portability of codes. It was felt,\nhowever, that FORTRAN was used mainly for historical reasons and new, more powerful languages would be needed to fully exploit\nthe potential of the electronic computer. As we all know, CERN was\nnot affected by, or it missed completely, the language explosion\nwhich started in the early 60's. ALGOL, Lisp, PL/I, PASCAL, Modula\nII, ADA, C, PROLOG, etc... did not raise above the level of\nminority cultures. FORTRAN evolved through its versions II, IV, 66,\n77, 8X, and it still dominates the CERN programming landscape. It took some time to saturate the 709, but it was already clear\nthat young physicists were becoming addicted. It was at that time\nthat the first embryonic Operating System appeared under the name\nof FORTRAN Monitor System. Many other important events occurred\nin the early 60's, such as the connection of computers on-line to\nfilm measuring devices including the very fast automatic flying\nspot digitizers (HPD, Luciole, etc..) forerunners of the modern\nimage digitizers and the first attempts to connect computers\ndirectly to experimental equipment (on-line experiments). The IBM\n709 was operated on-line to an HPD to measure both bubble and spark\nchamber films. In September 1963 the 709 was replaced by a 7090, a transistorized version of the same machine, about four\ntimes more powerful. It was at that time that the investments and the efforts started\nto pay off. Over 300 000 frames of spark chamber film were\nautomatically scanned and measured in record time using an HPD\nFlying Spot Digitizer on-line to the 7090. At about the same time\ncomputers were connected on-line to experiments to monitor the\nequipment and to collect digital data from the first filmless\ndetectors (e.g. sonic spark chambers) onto magnetic tape. The first\nsuccessful demonstrations with fully auto automatic digital pattern\nrecognition showed that computers could be programmed to replace\nslow human operators in a variety of tasks. Stories about computers\ndoing things faster, better and more reliably than human beings got\naround producing the usual mixture re of emotional reactions. In\n1970 the European Physics Society held a Conference at CERN on the\n'Impact of Computers on Physics' and I remember the reassuring\nstatement of an eminent physicist that 'so far computers have not\nsignificantly contributed to any discovery'. It was going to take\nanother decade to see the HEP community wholeheartedly accepting\nthe computer as a critical component of their research and\nadmitting it to their current technological foundation trilogy: accelerators, detectors and computers. 1970 was also the year when the 'CERN Computing and Data\nHandling School' was launched to educate young physicists and\nstimulate the sharing of computing experience between high-energy\nphysicists and computer scientists. It turned out to be an\nexcellent idea. The School is still alive and well, fulfilling a\nclear need. As to the cross-fertilization across the\nphysics/computer science boundary, it has developed into an ideal\npartnership. Actually the two disciplines have influenced each other from the\nvery beginning. It was the physicist Bruno Rossi who built the\nfirst logic circuits which then were developed into computer\nhardware, and physicists have always been among the most\ndemanding consumers of computer cycles. Enrico Fermi, when asked in\nthe early fifties which research project would he recommend to the\nyoung Italian physicists, told them to design and build a computer.\nIndeed, physics research could not have become what it is without\nthe computer, and conversely, the development of the computer has\nbeen deeply influenced by the needs and vision of basic\nresearch. The study of the fundamental properties of elementary matter\ninvolves the frontiers of human knowledge and pushes the technology\nto the limit of what is possible. Computer scientists have been\nplaying with models and formalisms, architectures and languages,\ninventing tools and methodologies of a rather theoretical nature\nand they have been sometimes accused of developing general\nsolutions in search of specific problems. When a dense problem\nspace meets a rich solution space some good news can be\nexpected... Evidence of synergistic effects has been accumulating\never since the beginning of the information era. High-energy\nphysics and information technology are among those disciplines\nwhich, in the second half of our century, have shown the most\nimpressive advances. Appendix 1 (part 1) All the major computers having served in the CERN Computer\nCentre in the period 1958-1988 are listed in chronological order,\ntogether with some configuration details and their characteristic\nfeatures. FERRANTI 'Mercury' [1958-1965] First generation vacuum tube machine (60 microsec clock\ncycle, 2 cycles to load or store, 3 cycles to add and 5 cycles to\nmultiply 40 bit longwords, no hardware division) with magnetic core\nstorage (1024 40-bit words, 120 microsec access time). Mercury's\nprocessor had floating point arithmetic and a B-Register (index\nregister). Magnetic drum auxiliary storage (16 Kwords of 40 bits,\n8.75 msec average latency, 64 longwords transferred per\nrevolution). Paper tape I/0. Two Ampex magtape units added in 1962. Autocode compiler. At the end of its career it was\nconnected on-line to an experiment (Missing Mass Spectrometer). In\n1966 the Mercury was shipped to Poland as a gift to the Academy of\nMining and Metallurgy at Cracow. IBM 709 [1961-1963] Vacuum tube machine ( 12 microsec clock cycle, 2 cycles to\nadd and 15 on average to multiply 36 bit integers, hardwired\ndivision and floating point arithmetic, index registers) with core\nstorage (32 Kwords of 36 bits, 24 microsec access time). Card\nreader (250 cpm) and card punch (100 cpm). Line printer. Magtape\nunits (7 tracks, 75 ips, 200 bpi). Introduction of the Data\nChannel. FORTRAN compiler. FORTRAN Monitor System. IBM 7090 [1963-1965] Transistorized second-generation machine ( 2.18 microsec clock cycle) with core storage (32 Kwords of 36 bits, 4.36 microsec\naccess time). Card 1/0, Tape units (7 tracks, 112.5 ips, 200/556\nbpi). Eight Data Channels. Interrupt System. FORTRAN compiler.\nBasic Monitor Operating System (IBSYS). Connected on-line to Flying\nSpot Digitizers (HPD and Luciole) to measure bubble and spark\nchamber films. CDC 6600 [1965-1975] Serial Number 3 (pre-production series machine). Transistor\nmachine designed by Seymour Cray and very compact for its time. CPU\nclock cycle 100 nsec . Core memory: 128 Kwords of 60 bits.\nMemory access 1 microsec, but independent memory banks allowed for\nup to one access per clock cycle. Instruction prefetch. Ten\noverlapping functional units. Ten autonomous peripheral processor\nunits (PPU's) each with 4K of 12-bit words core memory. Huge disks\nover one meter in diameter holding 500 million bits. Tape Units\n(half inch tape, 7 tracks, 200, 556 and 800 bpi, and one inch tape,\n14 tracks, 800 bpi). High-speed card reader (1200 cpm). First multi-programmed machine in the Computer Centre. However,\nSIPROS multiprogramming operating system was abandoned by Control\nData. Basic SIPROS operating system had to be made at CERN. Then\nChippewa OS (COS) was installed. It evolved to SCOPE which was\neventually used after adapting it to CERN needs. This resulted in a\nnon-trivial amount of changes, thus deserving the renaming to CERN\nSCOPE. The 6600 was connected to various FSD systems and to two\non-line computers, the SDS920 and the IBM 1800, via CERN-made data\nlinks. In terms of processing capacity the 6600 was about three\nquarters of a CERN unit or ten times the 7090. The change-over from the IBM 7090 was planned to take three\nmonths starting in January 1965. Major engineering overhauls had to\nbe done instead during the first few years and ended up in a\ntwo-months shut-down in 1968 in order to modify the 6600 to\nincorporate logic and packaging improvements which had been\nintroduced in the production machines. During this long period of\nstruggling with hardware instabilities and software development and\nchanges, computing work was done partly by sending jobs to outside\ncomputers and partly by processing data on a CDC 3400, and later on\na 3800, temporarily made available at CERN by Control Data. CDC 3800 [1966-1968] The 3800 was a member of the 3000 series CDC family of\ncomputers, incompatible with the 6000 series machines. More\nconventional than the 6600, the 3800 had a 48-bit architecture. The\ncore memory (64 Kwords) was replaced by a faster one (800 nsec)\nduring its staying at CERN. This machine was eventually acquired by\nthe State of Geneva and installed at the local University. At CERN\nit was replaced by a CDC 6400. It is worth noting that CERN\nacquired other machines of the 3000 s series, e.g. a 3100 for the\nFOCUS project offering semi-interactive facilities and quick\nsampling of experimental data at the central computers, and a 3200\nfor interactive graphics applications."
    },
    {
      "tag": "div",
      "text": "For matters related to this article please contact the author. Cnl.Editor@cern.ch"
    },
    {
      "tag": "p",
      "text": "CERN-CNL-2001-002 Vol. XXXVI, issue no 2"
    },
    {
      "tag": "div",
      "text": "Last Updated on Fri Aug 03 12:02:33 CEST 2001. Copyright Â© CERN 2001 -- European Organization for Nuclear Research"
    }
  ]
}